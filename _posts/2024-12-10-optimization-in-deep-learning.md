---
layout: post
title: "Optimization in Deep Learning"
date: 2024-12-10 16:15:00 +0800
tags: [optimization, deep-learning, SGD, Adam, training]
author: Lausen
reading_time: 18
excerpt: "simple excerpt here."
---

Training deep neural networks is fundamentally an optimization problem. We start with a randomly initialized model and iteratively adjust its parameters to minimize a loss function. The choice of optimization algorithm can dramatically affect both training speed and final model performance.